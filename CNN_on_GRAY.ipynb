{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grayscale models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, MaxPooling3D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from keras.applications import MobileNet\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'cnn_train'\n",
    "train_path = os.path.join(train_dir, '*g')\n",
    "\n",
    "train_imgsNom = glob.glob(train_path)\n",
    "train_labels = [int(name[-5]) for name in train_imgsNom]\n",
    "train_imgs = np.array([np.array(cv2.imread(img, 0)) for img in train_imgsNom])\n",
    "train_imgs = train_imgs.reshape(tuple(np.append(train_imgs.shape, 1)))\n",
    "\n",
    "train_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = 'cnn_test'\n",
    "test_path = os.path.join(test_dir, '*g')\n",
    "\n",
    "test_imgsNom = glob.glob(test_path)\n",
    "test_labels = np.array([int(name[-5]) for name in test_imgsNom])\n",
    "test_imgs = np.array([np.array(cv2.imread(img, 0)) for img in test_imgsNom])\n",
    "test_imgs = test_imgs.reshape(tuple(np.append(test_imgs.shape, 1)))\n",
    "\n",
    "test_imgs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For image loading and preprocessing see:\n",
    "https://keras.io/preprocessing/image/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 60, 60\n",
    "\n",
    "print('train_imgs shape:', train_imgs.shape)\n",
    "print(train_imgs.shape[0], 'train samples')\n",
    "print(test_imgs.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "train_label = keras.utils.to_categorical(train_labels, num_classes)\n",
    "# val_label = keras.utils.to_categorical(val_labels, num_classes)\n",
    "test_label = keras.utils.to_categorical(test_labels, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The model used by DNT ###\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Conv2D(4, kernel_size=(5, 5),\n",
    "                 activation='relu',\n",
    "                 input_shape=(img_rows,img_cols,1)))\n",
    "model2.add(Conv2D(5, (3, 3), activation='relu', kernel_initializer = 'random_normal'))\n",
    "model2.add(Dropout(0.3))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(24*24*5, activation='relu', kernel_initializer = 'random_normal'))\n",
    "model2.add(Dense(num_classes, activation='softmax', kernel_initializer = 'random_normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Our improvement of DNT ###\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(Conv2D(4, kernel_size=(5, 5),\n",
    "                 activation='relu',\n",
    "                 input_shape=(img_rows,img_cols,1)))\n",
    "model3.add(Conv2D(5, (3, 3), activation='relu', kernel_initializer = 'random_normal'))\n",
    "model3.add(MaxPooling2D(pool_size=(4,4), padding='valid')) # Added\n",
    "model3.add(Dropout(0.3))\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(16, activation='relu', kernel_initializer = 'random_normal')) # 24*24*5 to 16\n",
    "model3.add(Dense(num_classes, activation='softmax', kernel_initializer = 'random_normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### B-Human ball-detector model ###\n",
    "\n",
    "model4 = Sequential()\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Conv2D(4, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(img_rows,img_cols,1),\n",
    "                 kernel_initializer = 'random_normal'))\n",
    "model4.add(MaxPooling2D(pool_size=(2,2), padding='valid'))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Conv2D(8, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 kernel_initializer = 'random_normal'))\n",
    "model4.add(MaxPooling2D(pool_size=(2,2), padding='valid'))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Conv2D(8, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 strides=(2, 2),\n",
    "                 kernel_initializer = 'random_normal'))\n",
    "model4.add(MaxPooling2D(pool_size=(2,2), padding='valid'))\n",
    "model4.add(Flatten())\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Dense(num_classes, activation='softmax', kernel_initializer = 'random_normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### B-Human 2###\n",
    "\n",
    "model5 = Sequential()\n",
    "model5.add(MaxPooling2D(pool_size=(2,2), padding='valid')) # Added\n",
    "model5.add(BatchNormalization())\n",
    "model5.add(Conv2D(4, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(img_rows/2,img_cols/2, 1),\n",
    "                 kernel_initializer = 'random_normal'))\n",
    "model5.add(MaxPooling2D(pool_size=(2,2), padding='valid'))\n",
    "model5.add(BatchNormalization())\n",
    "model5.add(Conv2D(8, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 kernel_initializer = 'random_normal'))\n",
    "model5.add(MaxPooling2D(pool_size=(2,2), padding='valid'))\n",
    "model5.add(BatchNormalization())\n",
    "model5.add(Conv2D(8, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 strides=(2, 2),\n",
    "                 kernel_initializer = 'random_normal'))\n",
    "model5.add(MaxPooling2D(pool_size=(2,2), padding='valid'))\n",
    "model5.add(Flatten())\n",
    "model5.add(BatchNormalization())\n",
    "model5.add(Dense(num_classes, activation='softmax', kernel_initializer = 'random_normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### B-Human 3###\n",
    "\n",
    "model6 = Sequential()\n",
    "model6.add(MaxPooling2D(pool_size=(2,2), padding='valid'))\n",
    "model6.add(BatchNormalization())\n",
    "model6.add(Conv2D(8, kernel_size=(3, 3), # 4 to 8\n",
    "                 activation='relu',\n",
    "                 input_shape=(img_rows,img_cols,1),\n",
    "                 kernel_initializer = 'random_normal'))\n",
    "model6.add(MaxPooling2D(pool_size=(2,2), padding='valid'))\n",
    "model6.add(BatchNormalization())\n",
    "model6.add(Conv2D(8, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 kernel_initializer = 'random_normal'))\n",
    "model6.add(MaxPooling2D(pool_size=(2,2), padding='valid'))\n",
    "model6.add(BatchNormalization())\n",
    "model6.add(Conv2D(8, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 strides=(2, 2),\n",
    "                 kernel_initializer = 'random_normal'))\n",
    "model6.add(MaxPooling2D(pool_size=(2,2), padding='valid'))\n",
    "model6.add(Flatten())\n",
    "model6.add(BatchNormalization())\n",
    "model6.add(Dense(128, activation='relu', kernel_initializer = 'random_normal'))\n",
    "model6.add(Dense(num_classes, activation='softmax', kernel_initializer = 'random_normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### B-Human 4###\n",
    "\n",
    "model7 = Sequential()\n",
    "model7.add(Conv2D(8, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(img_rows,img_cols,1),\n",
    "                 kernel_initializer = 'random_normal'))\n",
    "model7.add(MaxPooling2D(pool_size=(2,2), padding='valid'))\n",
    "model7.add(BatchNormalization())\n",
    "model7.add(Conv2D(8, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 kernel_initializer = 'random_normal'))\n",
    "model7.add(MaxPooling2D(pool_size=(2,2), padding='valid'))\n",
    "model7.add(BatchNormalization())\n",
    "model7.add(Conv2D(16, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 kernel_initializer = 'random_normal'))\n",
    "model7.add(MaxPooling2D(pool_size=(2,2), padding='valid'))\n",
    "model7.add(BatchNormalization())\n",
    "model7.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 strides=(2, 2),\n",
    "                 kernel_initializer = 'random_normal'))\n",
    "model7.add(MaxPooling2D(pool_size=(2,2), padding='valid'))\n",
    "model7.add(Flatten())\n",
    "model7.add(BatchNormalization())\n",
    "model7.add(Dense(128, activation='relu', kernel_initializer = 'random_normal'))\n",
    "model7.add(Dense(num_classes, activation='softmax', kernel_initializer = 'random_normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 30\n",
    "\n",
    "current_model = model2\n",
    "\n",
    "current_model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "current_model.fit(train_imgs, train_label,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_split=.2)\n",
    "\n",
    "score = current_model.evaluate(test_imgs, test_label, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "current_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save current model (uncomment to save)\n",
    "# current_model.save('current_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speed measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import timeit\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flops(model):\n",
    "    run_meta = tf.RunMetadata()\n",
    "    opts = tf.profiler.ProfileOptionBuilder.float_operation()\n",
    "\n",
    "    # We use the Keras session graph in the call to the profiler.\n",
    "    flops = tf.profiler.profile(graph=K.get_session().graph,\n",
    "                                run_meta=run_meta, cmd='op', options=opts)\n",
    "\n",
    "    return flops.total_float_ops  # Prints the \"flops\" of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = []\n",
    "for i in range(1000000):\n",
    "    start = timeit.default_timer()\n",
    "    current_model.predict(np.array(test_imgs[:0]))\n",
    "    end = timeit.default_timer()\n",
    "    times.append(end - start)\n",
    "print(np.mean(times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_flops(current_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from texttable import Texttable\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred_test =  current_model.predict(test_imgs)\n",
    "predT = np.array(pred_test[:,0]) < 0.5\n",
    "realT = test_labels == 1\n",
    "print(sum(predT == realT))\n",
    "print(len(predT))\n",
    "\n",
    "def evalMatrix(predT,realT):\n",
    "    t = Texttable()\n",
    "    t.add_rows([['Pred\\Real', 'True', 'False '], ['True', sum(predT & realT), sum(predT & (~realT)) ], ['False',  sum(~predT & realT), sum(~ predT & ~ realT) ]])\n",
    "    print(t.draw())\n",
    "evalMatrix(np.array(predT),np.array(realT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(test_labels)\n",
    "plt.imshow(test_imgs[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
