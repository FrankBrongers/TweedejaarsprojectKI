{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This is the main execution file of the project.\n",
    "\n",
    "Given an image from the robot's camera, it will return the coordinates of the center of the classified part of a robot.\n",
    "\n",
    "This will be done in 4 steps:\n",
    "\n",
    "1. Segmentation of the input image\n",
    "\n",
    "2. Blob detection\n",
    "\n",
    "3. Classification by CNN\n",
    "\n",
    "4. Return coordinates\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import keras\n",
    "import glob\n",
    "import random\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn import linear_model, datasets\n",
    "from __future__ import division \n",
    "from keras.models import load_model\n",
    "from PIL import Image, ImageOps\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.feature import blob_dog, blob_log, blob_doh\n",
    "import os\n",
    "\n",
    "# Import trained CNN\n",
    "model = load_model('current_cnn.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for Step 1: Segmentation ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Calculates angle between two lines given the points on the y-axis\n",
    "'''\n",
    "def get_angle(points1,points2):\n",
    "        p1 = points1[0]\n",
    "        p2 = points2[0]\n",
    "        L1 = line(p1, points1[1])\n",
    "        L2 = line(p2, points2[1])\n",
    "\n",
    "        p0 = intersection(L1,L2)\n",
    "        if p0 == False:\n",
    "            return False,False\n",
    "        v0 = np.array(p1) - np.array(p0)\n",
    "        v1 = np.array(p2) - np.array(p0)\n",
    "\n",
    "        angle = np.math.atan2(np.linalg.det([v0,v1]),np.dot(v0,v1))\n",
    "        return p0, np.degrees(angle)\n",
    "\n",
    "'''\n",
    "\n",
    "'''\n",
    "def line(p1, p2):\n",
    "    A = (p1[1] - p2[1])\n",
    "    B = (p2[0] - p1[0])\n",
    "    C = (p1[0]*p2[1] - p2[0]*p1[1])\n",
    "    return A, B, -C\n",
    "\n",
    "def intersection(L1, L2):\n",
    "    D  = L1[0] * L2[1] - L1[1] * L2[0]\n",
    "    Dx = L1[2] * L2[1] - L1[1] * L2[2]\n",
    "    Dy = L1[0] * L2[2] - L1[2] * L2[0]\n",
    "    if D != 0:\n",
    "        x = Dx / D\n",
    "        y = Dy / D\n",
    "        return x,y\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def findgreen(image, modus = False):\n",
    "    thres = 63\n",
    "    if not modus:\n",
    "        # find sample methods\n",
    "        ys = np.random.choice(np.linspace(200,479,278),100)\n",
    "        xs = np.random.choice(np.linspace(0,600,601),100)\n",
    "        values = [image[int(ys[i]),int(xs[i])] for i in range(100)]\n",
    "        countVal = Counter(values)\n",
    "        modi = countVal.most_common(10)\n",
    "        i =0\n",
    "        modus = modi[0][0]\n",
    "        while modus < 100 and i<9:\n",
    "            i+= 1\n",
    "            modus = modi[i][0]\n",
    " \n",
    "    # optie om via arrays sneller te maken\n",
    "    minmod = np.array(np.array(modus) - thres)\n",
    "    maxmod = np.array(np.array(modus) + thres)\n",
    "    \n",
    "\n",
    "    nimage = image[:].copy()\n",
    "    \n",
    "    # Via opencv\n",
    "    nimage = cv2.inRange(image,minmod,maxmod)\n",
    "    \n",
    "    return nimage, modus\n",
    "\n",
    "def getField2(img):\n",
    "    blur =cv2.GaussianBlur(img,(71,71),10)\n",
    "    hsv =  cv2.cvtColor(blur,cv2.COLOR_BGR2HSV)\n",
    "    h,s,v = cv2.split(hsv)\n",
    "    greenFiltered,modus = findgreen(np.array(s))\n",
    "    edge = cv2.Canny(greenFiltered, 20,40)\n",
    "    ransac = linear_model.RANSACRegressor()\n",
    "    y,x = np.argwhere(edge == 255)[:,0], np.argwhere(edge == 255)[:,1]\n",
    "    \n",
    "    #preprocess:\n",
    "    bot_mask = y < 400\n",
    "    xp = x[bot_mask]\n",
    "    yp = y[bot_mask]\n",
    "    data = np.array([xp,yp]).T\n",
    "    \n",
    "    # use RANSAC to find field line\n",
    "    from skimage.measure import LineModelND, ransac\n",
    "    model_robust, inliers_mask = ransac(data, LineModelND, min_samples=2, residual_threshold=1, max_trials=300)\n",
    "    outliers_mask = inliers_mask == False\n",
    "    yin = data.T[1][inliers_mask]\n",
    "    xin = data.T[0][inliers_mask]\n",
    "    \n",
    "    # from points get line:\n",
    "    Ny,Nx = np.shape(edge)\n",
    "    xdiff = xin[0] - xin[-1]\n",
    "    ydiff = yin[0] - yin[-1]\n",
    "    if xdiff == 0 or ydiff == 0:\n",
    "        # in case line is horizontal or vertical\n",
    "        exit()\n",
    "    a = ydiff/xdiff\n",
    "    b = yin[0] - xin[0]*a\n",
    "    line = a*np.arange(Nx) + b\n",
    "\n",
    "    # Do same for second line:\n",
    "    data2 = data[outliers_mask]\n",
    "    model_robust, inliers_mask = ransac(data2, LineModelND, min_samples=2, residual_threshold=1, max_trials=300)\n",
    "    yin = data2.T[1][inliers_mask]\n",
    "    xin = data2.T[0][inliers_mask]\n",
    "\n",
    "    # from points get line:\n",
    "    Ny,Nx = np.shape(edge)\n",
    "    xdiff = xin[0] - xin[-1]\n",
    "    ydiff = yin[0] - yin[-1]\n",
    "    if xdiff == 0 or ydiff == 0:\n",
    "        # in case line is horizontal or vertical\n",
    "        exit()\n",
    "    a = ydiff/xdiff\n",
    "    b = yin[0] - xin[0]*a\n",
    "    line2 = a*np.arange(Nx) + b\n",
    "\n",
    "    # green -> black MASK1\n",
    "    hsv =  cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
    "    h,s,v = cv2.split(hsv)\n",
    "    greenMask, _ = findgreen(np.array(s), modus)\n",
    "    img = cv2.bitwise_and(img,img,mask = ~greenMask)\n",
    "    \n",
    "    # Area enclosed by first line\n",
    "    # Polygon coordinates [[top left], [top right], [bottom right], [bottom left]]\n",
    "    area1 = np.array([[[0,0],[Nx,0],[Nx,line[-1]],[0, line[0]]]], dtype=np.int32)\n",
    "    # ... second line\n",
    "    \n",
    "\n",
    "    # Using tilde (~) to fill in either the field or the non-field part\n",
    "    original_copy = img\n",
    "    cv2.fillPoly(original_copy, area1, 0)\n",
    "    p0, angle = get_angle([[0,line[0]],[Nx, line[-1]]], [[0,line2[0]],[Nx, line2[-1]]] )\n",
    "    if not(p0 == False or p0[0] < 0 or p0[0]> Ny or p0[1] < 0 or p0[1] > Nx or abs(angle) <1):\n",
    "        # no second line\n",
    "        area2 = np.array( [[[0,0],[Nx,0],[Nx,line2[-1]],[0, line2[0]]]], dtype=np.int32 )\n",
    "        cv2.fillPoly(original_copy, area2, 0)\n",
    "    \n",
    "    grayImage = cv2.cvtColor(original_copy, cv2.COLOR_BGR2GRAY)\n",
    "    (thresh, bw) = cv2.threshold(grayImage, 50, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    return bw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for Step 2: Blob Detection ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Given binary image, original image and scale-size of candidate areas, returns the found blobs, and saves the found regions\n",
    "    into the current folder, and gives the filenames for further processing.\n",
    "'''\n",
    "def get_candidate_areas(bin_img,im,size):\n",
    "    blobs = blob_doh(bin_img, max_sigma=50, min_sigma=30, threshold=.01, num_sigma=10)\n",
    "    \n",
    "    found_imgs, squares = get_roi_imgs_blobs(blobs,im)\n",
    "    \n",
    "    scaled_imgs = scale_imgs(found_imgs, size)\n",
    "    \n",
    "    candidate_file_names = imgs_to_files(scaled_imgs)\n",
    "    \n",
    "    return blobs, candidate_file_names\n",
    "\n",
    "\n",
    "'''\n",
    "Given detected blobs and the original image, returns the bounding boxes and images of the bounding boxes\n",
    "'''\n",
    "def get_roi_imgs_blobs(blobs,im_ori):\n",
    "    squares = make_blob_square(blobs)\n",
    "    imgs = get_found_imgs(im_ori,squares)\n",
    "    \n",
    "    return imgs, squares\n",
    "\n",
    "'''\n",
    "Turns Squares around regions of interest into actual images\n",
    "'''    \n",
    "def get_found_imgs(im,squares):\n",
    "    found_imgs = []\n",
    "    for square in squares:\n",
    "        new_im = im[square[1]:square[1]+square[3], square[0]:square[0]+square[2]]\n",
    "        img = Image.fromarray(new_im, 'RGB').convert('LA')\n",
    "        found_imgs.append(img)\n",
    "    return found_imgs\n",
    "\n",
    "'''\n",
    "Returns the bounding boxes around found blobs\n",
    "'''\n",
    "def make_blob_square(blobs):\n",
    "    squares = []\n",
    "\n",
    "    for blob in blobs:\n",
    "        \n",
    "        y_cen, x_cen, rad = blob\n",
    "        \n",
    "        x = x_cen - math.floor(rad)\n",
    "        y = y_cen - math.floor(rad)\n",
    "        \n",
    "        w = rad*2\n",
    "        h = rad*2\n",
    "        \n",
    "        xsiz= 479 - w\n",
    "        ysiz = 639 - h\n",
    "        \n",
    "        if x < 0:\n",
    "            x = 0\n",
    "        elif x > xsiz:\n",
    "            x = xsiz\n",
    "        if y < 0:\n",
    "            y = 0\n",
    "        elif y > ysiz:\n",
    "            y = ysiz\n",
    "        square = [int(x),int(y),int(w),int(h)]\n",
    "        squares.append(square)\n",
    "    return squares\n",
    "\n",
    "\n",
    "'''\n",
    "Scales found images into fixed resolution\n",
    "'''\n",
    "def scale_imgs(imgs,size):\n",
    "    scaled_imgs = []\n",
    "    for im in imgs:\n",
    "        if size == 0:\n",
    "            new_im = im\n",
    "        else:\n",
    "            new_im = ImageOps.fit(im, size, Image.ANTIALIAS)\n",
    "        scaled_imgs.append(new_im)\n",
    "    return scaled_imgs\n",
    "\n",
    "\n",
    "'''\n",
    "Saves found images to files in current directory.\n",
    "'''\n",
    "def imgs_to_files(imgs):\n",
    "    count = 0\n",
    "    names = []\n",
    "    for im in imgs:\n",
    "#         print(\"imgs bitch\", im)\n",
    "        name = \"canditate_\"+ str(count) + \".png\"\n",
    "        im.save(name) \n",
    "        names.append(name)\n",
    "        count += 1\n",
    "    return names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for Step 3: Classification by CNN ### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Gives filenames of candidate areas saved in current directory and a threshold for classification, \n",
    "    return what the trained CNN thinks are robots and what aren't.\n",
    "'''\n",
    "def get_predictions(candidate_file_names, thresh): \n",
    "    imgs = []\n",
    "    for can in candidate_file_names:\n",
    "        im = cv2.imread(can,0)\n",
    "        im2 = np.array(im)\n",
    "        print(len(im))\n",
    "        print(im2.shape)\n",
    "        print(im,\"hi\")\n",
    "    \n",
    "        imgs.append(im)\n",
    "        \n",
    "    imgs = np.array(imgs)\n",
    "    imgs = imgs.reshape(tuple(np.append(imgs.shape, 1)))\n",
    "    imgs = np.asarray(imgs)\n",
    "    predictions = model.predict(imgs)\n",
    "    predictions = np.array(predictions[:,0]) < thresh\n",
    "    return predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for Step 4: Return Coordinates ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Of all the candidate areas that were classified as being a robot the center coordinates will be returned by this function.\n",
    "'''\n",
    "def return_coords_robots(blob_coords,predictions):\n",
    "    coords = []\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] == True:\n",
    "            blob_coord = blob_coords[i]\n",
    "            x = blob_coord[1]\n",
    "            y = blob_coord[0]\n",
    "            blob_coord = (int(x),int(y))\n",
    "            coords.append(blob_coord)\n",
    "    \n",
    "    return coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Execution ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_robots(input_image):\n",
    "    im = cv2.imread(input_image)\n",
    "    \n",
    "    #Step 1: Segmentation\n",
    "    bin_img = getField2(im)\n",
    "    \n",
    "    #Step 2: Blob Detection\n",
    "    size = (60,60)#size of candidate areas\n",
    "    blob_coords, candidate_file_names = get_candidate_areas(bin_img,im,size)\n",
    "    \n",
    "    #Step 3: Classifacation by CNN\n",
    "    threshold = 0.5 #Threshold for classification\n",
    "    predictions = get_predictions(candidate_file_names,threshold)\n",
    "\n",
    "    #Step 4: Return Coordinates\n",
    "    coords = return_coords_robots(blob_coords, predictions)\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for Plotting ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_found_robots(coords, im):\n",
    "    im = cv2.imread(im)\n",
    "    x = [x[0] for x in coords]\n",
    "    y = [y[1] for y in coords]\n",
    "    \n",
    "    plt.imshow(im)\n",
    "    plt.scatter(x,y, s=60, c='magenta')\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAO OR NEVER! #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#An image as seen by a robot\n",
    "input_image = 'imageset_131/16_02_2018__11_18_08_0046_upper.png'\n",
    "\n",
    "robots = detect_robots(input_image)\n",
    "print(robots)\n",
    "plot_found_robots(robots,input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = cv2.imread('canditate_2.png',0)\n",
    "plt.imshow(test)\n",
    "print(test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
