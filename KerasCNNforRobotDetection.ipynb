{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models, clean code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, MaxPooling3D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from keras.applications import MobileNet\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'cnn_train'\n",
    "train_path = os.path.join(train_dir, '*g')\n",
    "\n",
    "train_imgsNom = glob.glob(train_path)\n",
    "train_labels = [int(name[-5]) for name in train_imgsNom]\n",
    "train_imgs = np.array([np.array(cv2.imread(img, cv2.IMREAD_GRAYSCALE)) for img in train_imgsNom])\n",
    "train_imgs = train_imgs.reshape(tuple(np.append(train_imgs.shape, 1)))\n",
    "\n",
    "train_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = 'cnn_test'\n",
    "test_path = os.path.join(test_dir, '*g')\n",
    "\n",
    "test_imgsNom = glob.glob(test_path)\n",
    "test_labels = np.array([int(name[-5]) for name in test_imgsNom])\n",
    "test_imgs = np.array([np.array(cv2.imread(img, cv2.IMREAD_GRAYSCALE)) for img in test_imgsNom])\n",
    "test_imgs = test_imgs.reshape(tuple(np.append(test_imgs.shape, 1)))\n",
    "\n",
    "test_imgs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For image loading and preprocessing see:\n",
    "https://keras.io/preprocessing/image/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 60, 60\n",
    "\n",
    "print('train_imgs shape:', train_imgs.shape)\n",
    "print(train_imgs.shape[0], 'train samples')\n",
    "print(test_imgs.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "train_label = keras.utils.to_categorical(train_labels, num_classes)\n",
    "# val_label = keras.utils.to_categorical(val_labels, num_classes)\n",
    "test_label = keras.utils.to_categorical(test_labels, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mobile = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Basic CNN ###\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu', \n",
    "                 input_shape=(img_rows,img_cols,1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer = 'random_normal'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu', kernel_initializer = 'random_normal'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax', kernel_initializer = 'random_normal'))\n",
    "\n",
    "# Total params: 6,441,730\n",
    "# Na 30 epochs: 0.69158878727494"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The model used by DNT ###\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Conv2D(4, kernel_size=(5, 5),\n",
    "                 activation='relu',\n",
    "                 input_shape=(img_rows,img_cols,1)))\n",
    "model2.add(Conv2D(5, (3, 3), activation='relu', kernel_initializer = 'random_normal'))\n",
    "model2.add(Dropout(0.3))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(24*24*5, activation='relu', kernel_initializer = 'random_normal'))\n",
    "model2.add(Dense(num_classes, activation='softmax', kernel_initializer = 'random_normal'))\n",
    "\n",
    "# Total params: 41,999,331\n",
    "# Na 30 epochs 0.7242990676487717"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Our improvement of DNT ###\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(Conv2D(4, kernel_size=(5, 5),\n",
    "                 activation='relu',\n",
    "                 input_shape=(img_rows,img_cols,1)))\n",
    "model3.add(Conv2D(5, (3, 3), activation='relu', kernel_initializer = 'random_normal'))\n",
    "model3.add(MaxPooling2D(pool_size=(4,4), padding='valid'))\n",
    "model3.add(Dropout(0.3))\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(16, activation='relu', kernel_initializer = 'random_normal'))\n",
    "model3.add(Dense(num_classes, activation='softmax', kernel_initializer = 'random_normal'))\n",
    "\n",
    "# Total params: 2,442,531\n",
    "# Na 30 epochs: 0.8644859813084113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### B-Human ball-detector model ###\n",
    "\n",
    "model4 = Sequential()\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Conv2D(4, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(img_rows,img_cols,1),\n",
    "                 kernel_initializer = 'random_normal'))\n",
    "model4.add(MaxPooling2D(pool_size=(2,2), padding='valid'))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Conv2D(8, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "#                  input_shape=(img_rows,img_cols,3),\n",
    "                 kernel_initializer = 'random_normal'))\n",
    "model4.add(MaxPooling2D(pool_size=(2,2), padding='valid'))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Conv2D(8, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "#                  input_shape=(img_rows,img_cols,3),\n",
    "                 strides=(2, 2),\n",
    "                 kernel_initializer = 'random_normal'))\n",
    "model4.add(MaxPooling2D(pool_size=(2,2), padding='valid'))\n",
    "model4.add(Flatten())\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Dense(num_classes, activation='softmax', kernel_initializer = 'random_normal'))\n",
    "\n",
    "# Total params: 1,406\n",
    "# Na 30 epochs 0.8842592570516798"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### B-Human ball-detector model with max pooling first###\n",
    "\n",
    "model5 = Sequential()\n",
    "model5.add(MaxPooling2D(pool_size=(2,2), padding='valid'))\n",
    "model5.add(BatchNormalization())\n",
    "model5.add(Conv2D(4, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(img_rows,img_cols,1),\n",
    "                 kernel_initializer = 'random_normal'))\n",
    "model5.add(MaxPooling2D(pool_size=(2,2), padding='valid'))\n",
    "model5.add(BatchNormalization())\n",
    "model5.add(Conv2D(8, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "#                  input_shape=(img_rows,img_cols,3),\n",
    "                 kernel_initializer = 'random_normal'))\n",
    "model5.add(MaxPooling2D(pool_size=(2,2), padding='valid'))\n",
    "model5.add(BatchNormalization())\n",
    "model5.add(Conv2D(8, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "#                  input_shape=(img_rows,img_cols,3),\n",
    "                 strides=(2, 2),\n",
    "                 kernel_initializer = 'random_normal'))\n",
    "model5.add(MaxPooling2D(pool_size=(2,2), padding='valid'))\n",
    "model5.add(Flatten())\n",
    "model5.add(BatchNormalization())\n",
    "model5.add(Dense(num_classes, activation='softmax', kernel_initializer = 'random_normal'))\n",
    "\n",
    "# Total params: 1,022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 3\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "current_model = model\n",
    "\n",
    "current_model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# current_model.fit(train_imgs, train_label,\n",
    "#           batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "#           verbose=1,\n",
    "#           validation_split=.2,\n",
    "#           callbacks=[early_stopping])\n",
    "\n",
    "current_model.fit(train_imgs, train_label,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_split=.2)\n",
    "\n",
    "score = current_model.evaluate(test_imgs, test_label, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "current_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save current model 1705850201, 1706099677\n",
    "# current_model.save('current_cnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speed measures, not clean code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_meta = tf.RunMetadata()\n",
    "# with tf.Session(graph=tf.Graph()) as sess:\n",
    "#     keras.backend.set_session(sess)\n",
    "#     net = model5\n",
    "\n",
    "#     opts = tf.profiler.ProfileOptionBuilder.float_operation()    \n",
    "#     flops = tf.profiler.profile(sess.graph, run_meta=run_meta, cmd='op', options=opts)\n",
    "# # \n",
    "#     opts = tf.profiler.ProfileOptionBuilder.trainable_variables_parameter()    \n",
    "#     params = tf.profiler.profile(sess.graph, run_meta=run_meta, cmd='op', options=opts)\n",
    "\n",
    "#     print(\"{:,} --- {:,}\".format(flops.total_float_ops, params.total_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "current_model.predict(test_imgs)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "current_model.predict(test_imgs)\n",
    "end = time.perf_counter()\n",
    "execution_time = (end - start)\n",
    "execution_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timeit.default_timer()\n",
    "current_model.predict(test_imgs)\n",
    "end = timeit.default_timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flops(model):\n",
    "    run_meta = tf.RunMetadata()\n",
    "    opts = tf.profiler.ProfileOptionBuilder.float_operation()\n",
    "\n",
    "    # We use the Keras session graph in the call to the profiler.\n",
    "    flops = tf.profiler.profile(graph=K.get_session().graph,\n",
    "                                run_meta=run_meta, cmd='op', options=opts)\n",
    "\n",
    "    return flops.total_float_ops  # Prints the \"flops\" of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_flops(current_model))\n",
    "print(get_flops(model2))\n",
    "print(get_flops(model3))\n",
    "print(get_flops(model4))\n",
    "print(get_flops(model5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leons code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from texttable import Texttable\n",
    "\n",
    "pred_test =  current_model.predict(test_imgs)\n",
    "predT = np.array(pred_test[:,0]) < 0.5\n",
    "realT = test_labels == 1\n",
    "print(sum(predT == realT))\n",
    "print(len(predT))\n",
    "print(\"accuracy is:\",accuracy(predT,realT))\n",
    "# print(predT)\n",
    "# print(realT)\n",
    "def accuracy(predT, realT):\n",
    "    return sum(predT == realT)/ len(realT)    \n",
    "\n",
    "def precision(predT,realT):\n",
    "    # if it says robot is it robot?\n",
    "    return sum(predT and realT)/predT\n",
    "\n",
    "# def recall()\n",
    "\n",
    "def evalMatrix(predT,realT):\n",
    "    t = Texttable()\n",
    "    t.add_rows([['Pred\\Real', 'True', 'False '], ['True', sum(predT & realT), sum(predT & (~realT)) ], ['False',  sum(~predT & realT), sum(~ predT & ~ realT) ]])\n",
    "    print(t.draw())\n",
    "evalMatrix(np.array(predT),np.array(realT))\n",
    "# print(~realT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leon = np.array([True,True,False,False])\n",
    "Hm = np.array([True,False,False,True])\n",
    "print(leon & Hm)\n",
    "print(165/216)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2.compile(loss=keras.losses.categorical_crossentropy,\n",
    "#               optimizer=keras.optimizers.Adadelta(),\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# model2.fit(train_imgs, train_label,\n",
    "#           batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "#           verbose=1,\n",
    "#           validation_split=.2)\n",
    "# score = model2.evaluate(test_imgs, test_label, verbose=0)\n",
    "# print('Test loss:', score[0])\n",
    "# print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.array(test_imgsNom)[predT & (~realT)]\n",
    "# print(test_imgsNom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(test_labels)\n",
    "plt.imshow(test_imgs[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
