{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, MaxPooling3D\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'cnn_data_train'\n",
    "train_path = os.path.join(train_dir, '*g')\n",
    "\n",
    "train_imgsNom = glob.glob(train_path)\n",
    "train_labels = [int(name[-5]) for name in train_imgsNom]\n",
    "train_imgs = np.array([np.array(cv2.imread(img)) for img in train_imgsNom])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_dir = 'cnn_data_val'\n",
    "# val_path = os.path.join(val_dir, '*g')\n",
    "\n",
    "# val_imgs = glob.glob(val_path)\n",
    "# val_labels = [int(name[-5]) for name in val_imgs]\n",
    "# val_imgs = np.array([np.array(cv2.imread(img)) for img in val_imgs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = 'cnn_data_test'\n",
    "test_path = os.path.join(test_dir, '*g')\n",
    "\n",
    "test_imgsNom = glob.glob(test_path)\n",
    "test_labels = np.array([int(name[-5]) for name in test_imgsNom])\n",
    "test_imgs = np.array([np.array(cv2.imread(img)) for img in test_imgsNom])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For image loading and preprocessing see:\n",
    "https://keras.io/preprocessing/image/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 2\n",
    "epochs = 30\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 60, 60\n",
    "\n",
    "print('train_imgs shape:', train_imgs.shape)\n",
    "print(train_imgs.shape[0], 'train samples')\n",
    "print(test_imgs.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "train_label = keras.utils.to_categorical(train_labels, num_classes)\n",
    "# val_label = keras.utils.to_categorical(val_labels, num_classes)\n",
    "test_label = keras.utils.to_categorical(test_labels, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The trashy model used by fronk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu', \n",
    "                 input_shape=(img_rows,img_cols,3)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer = 'random_normal'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu', kernel_initializer = 'random_normal'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax', kernel_initializer = 'random_normal'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The model used by DNT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Conv2D(4, kernel_size=(5, 5),\n",
    "                 activation='relu',\n",
    "                 input_shape=(img_rows,img_cols,3)))\n",
    "model2.add(Conv2D(5, (3, 3), activation='relu', kernel_initializer = 'random_normal'))\n",
    "model2.add(Dropout(0.3))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(16, activation='relu', kernel_initializer = 'random_normal', input_shape=(24*24*5,)))\n",
    "model2.add(Dense(num_classes, activation='softmax', kernel_initializer = 'random_normal'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our improvement of DNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Conv2D(4, kernel_size=(5, 5),\n",
    "                 activation='relu',\n",
    "                 input_shape=(img_rows,img_cols,3)))\n",
    "model3.add(Conv2D(5, (3, 3), activation='relu', kernel_initializer = 'random_normal'))\n",
    "model3.add(MaxPooling2D(pool_size=(4,4), padding='valid'))\n",
    "model3.add(Dropout(0.3))\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(16, activation='relu', kernel_initializer = 'random_normal', input_shape=(24*24*5,)))\n",
    "model3.add(Dense(num_classes, activation='softmax', kernel_initializer = 'random_normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model3.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model3.fit(train_imgs, train_label,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_split=.2)\n",
    "score = model3.evaluate(test_imgs, test_label, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from texttable import Texttable\n",
    "\n",
    "\n",
    "# print(predT)\n",
    "# print(realT)\n",
    "def accuracy(predT, realT):\n",
    "    return sum(predT == realT)/ len(realT)    \n",
    "\n",
    "def precision(predT,realT):\n",
    "    # if it says robot is it robot?\n",
    "    return sum(predT and realT)/predT\n",
    "\n",
    "# def recall()\n",
    "\n",
    "def evalMatrix(predT,realT):\n",
    "    t = Texttable()\n",
    "    t.add_rows([['Pred\\Real', 'True', 'False '], ['True', sum(predT & realT), sum(predT & (~realT)) ], ['False',  sum(~predT & realT), sum(~ predT & ~ realT) ]])\n",
    "    print(t.draw())\n",
    "pred_test =  model3.predict(test_imgs)\n",
    "predT = np.array(pred_test[:,0]) < 0.5\n",
    "realT = test_labels == 1\n",
    "print(sum(predT == realT))\n",
    "print(len(predT))\n",
    "print(\"accuracy is:\",accuracy(predT,realT))\n",
    "evalMatrix(np.array(predT),np.array(realT))\n",
    "# print(~realT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leon = np.array([True,True,False,False])\n",
    "Hm = np.array([True,False,False,True])\n",
    "print(leon & Hm)\n",
    "print(165/216)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2.compile(loss=keras.losses.categorical_crossentropy,\n",
    "#               optimizer=keras.optimizers.Adadelta(),\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# model2.fit(train_imgs, train_label,\n",
    "#           batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "#           verbose=1,\n",
    "#           validation_split=.2)\n",
    "# score = model2.evaluate(test_imgs, test_label, verbose=0)\n",
    "# print('Test loss:', score[0])\n",
    "# print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model used by B-Human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# B-Human CNN komt hier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.array(test_imgsNom)[predT & (~realT)]\n",
    "# print(test_imgsNom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(test_labels)\n",
    "plt.imshow(test_imgs[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
